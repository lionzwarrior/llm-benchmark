
--- Async Benchmark Results ---
Model: llama3.2:3b
Workers: 10
Questions per worker: 1221
Total requests: 12210
Accuracy: 61.31%
Average latency: 0.506s
95th percentile latency: 1.439s
Throughput: 19.77 req/s
Total duration: 617.61s
