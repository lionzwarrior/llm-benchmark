
--- Async Benchmark Results ---
Model: llama3.2:3b
Workers: 10
Questions per worker: 1221
Total requests: 12210
Accuracy: 61.55%
Average latency: 0.515s
95th percentile latency: 1.392s
Throughput: 19.42 req/s
Total duration: 628.79s
