
--- Async Benchmark Results ---
Model: llama3.2:3b
Workers: 10
Questions per worker: 1221
Total requests: 12210
Accuracy: 61.84%
Average latency: 0.498s
95th percentile latency: 1.398s
Throughput: 20.07 req/s
Total duration: 608.37s
