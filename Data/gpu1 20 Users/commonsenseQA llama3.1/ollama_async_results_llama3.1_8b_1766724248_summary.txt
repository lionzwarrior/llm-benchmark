
--- Async Benchmark Results ---
Model: llama3.1:8b
Workers: 20
Questions per worker: 1221
Total requests: 24420
Accuracy: 74.99%
Average latency: 0.553s
95th percentile latency: 0.572s
Throughput: 36.17 req/s
Total duration: 675.14s

--- Token Throughput ---
Prompt tokens: 1842160
Generated tokens: 53804
Generation TPM: 5477.62
End-to-End TPM: 8440.86

--- Execution Time ---
Start time: 2025-12-26 04:44:08
End time:   2025-12-26 04:55:24
Total execution time: 675.35 seconds
