
--- Async Benchmark Results ---
Model: llama3.2:3b
Workers: 20
Questions per worker: 1221
Total requests: 24420
Accuracy: 61.76%
Average latency: 0.951s
95th percentile latency: 2.756s
Throughput: 21.02 req/s
Total duration: 1161.94s

--- Token Throughput ---
Prompt tokens: 2208460
Generated tokens: 156842
Generation TPM: 8980.01
End-to-End TPM: 6113.92

--- Execution Time ---
Start time: 2025-12-26 06:47:03
End time:   2025-12-26 07:06:25
Total execution time: 1162.15 seconds
