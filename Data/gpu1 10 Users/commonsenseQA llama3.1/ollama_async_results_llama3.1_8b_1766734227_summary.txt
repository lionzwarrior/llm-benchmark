
--- Async Benchmark Results ---
Model: llama3.1:8b
Workers: 10
Questions per worker: 1221
Total requests: 12210
Accuracy: 74.86%
Average latency: 0.330s
95th percentile latency: 0.361s
Throughput: 30.25 req/s
Total duration: 403.59s

--- Token Throughput ---
Prompt tokens: 921080
Generated tokens: 26856
Generation TPM: 4621.78
End-to-End TPM: 14133.63

--- Execution Time ---
Start time: 2025-12-26 07:30:27
End time:   2025-12-26 07:37:11
Total execution time: 403.69 seconds
