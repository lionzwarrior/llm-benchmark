
--- Async Benchmark Results ---
Model: llama3.2:3b
Workers: 10
Questions per worker: 1221
Total requests: 12210
Accuracy: 61.62%
Average latency: 0.509s
95th percentile latency: 1.386s
Throughput: 19.66 req/s
Total duration: 621.20s

--- Token Throughput ---
Prompt tokens: 1104230
Generated tokens: 80977
Generation TPM: 8591.51
End-to-End TPM: 11472.10

--- Execution Time ---
Start time: 2025-12-26 08:56:38
End time:   2025-12-26 09:06:59
Total execution time: 621.32 seconds
