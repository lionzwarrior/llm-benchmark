
--- Async Benchmark Results ---
Model: llama3.1:8b
Workers: 10
Questions per worker: 1221
Total requests: 12210
Accuracy: 75.02%
Average latency: 0.315s
95th percentile latency: 0.353s
Throughput: 30.50 req/s
Total duration: 400.27s

--- Token Throughput ---
Prompt tokens: 921080
Generated tokens: 26615
Generation TPM: 12141.66
End-to-End TPM: 14881.95

--- Execution Time ---
Start time: 2026-01-01 12:47:15
End time:   2026-01-01 12:53:55
Total execution time: 400.40 seconds
