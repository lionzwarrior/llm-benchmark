
--- Async Benchmark Results ---
Model: llama3.2:3b
Workers: 10
Questions per worker: 1221
Total requests: 12210
Accuracy: 62.29%
Average latency: 0.330s
95th percentile latency: 0.502s
Throughput: 29.73 req/s
Total duration: 410.73s

--- Token Throughput ---
Prompt tokens: 1104230
Generated tokens: 76231
Generation TPM: 15940.24
End-to-End TPM: 17668.44

--- Execution Time ---
Start time: 2026-01-01 13:11:06
End time:   2026-01-01 13:17:57
Total execution time: 410.87 seconds
